{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a79748f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo : document each import and its purpose\n",
    "#Pandas : for data manipulation \n",
    "#Sklearn : machine learning library for python programming language with the following to \n",
    "#import datasets,Initialize countvectorizer, compute the IDF values and compute the TFIDF scores.\n",
    "#Sklearn-TfidVectorizer -\n",
    "#Sklearn model_selection.train_test_split\n",
    "#Sklearn feature_extraction.CountVectorizer \n",
    "#Sklearn feature_extraction.TfidTransformer\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5b9fb1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read and load the excel file converted into a csv formatted \n",
    "#with the intents to match individual question\n",
    "def read_csv_data_file():\n",
    "    df = pd.read_csv('JHTechnicalAssignmentNutritionQuestions_Formatted.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "47faaa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-prepare the data to clean the dateset by removing any duplicates \n",
    "# And use the Pandas factorize method to encode an the intent with an  enumerated value\n",
    "# split the data into into random and test subsets\n",
    "\n",
    "def prepare_data_before_algorithm_application():\n",
    "    col =['Intent','Question']\n",
    "    y=read_csv_data_file()\n",
    "    y=y[col]\n",
    "    y=y[pd.notnull(y['Question'])]\n",
    "    y.columns = ['Intent','Question']\n",
    "    y['intent_id'] = y['Intent'].factorize()[0]\n",
    "    intent_id_df = y[['Intent','intent_id']].drop_duplicates().sort_values('intent_id')\n",
    "    intent_to_id = dict(intent_id_df.values)\n",
    "    id_to_intent = dict(intent_id_df[['intent_id','Intent']].values)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d0b58fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the text search algorithm to return the intent from the training data\n",
    "#use the TfidFvectorier to convert a collection of raw documents to a matrix of TF-IDF features(term \n",
    "# frequency-inverse document frequency)\n",
    "\n",
    "def algo_matcher():\n",
    "    \n",
    "    tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "    df=prepare_data_before_algorithm_application()\n",
    "    features = tfidf.fit_transform(df.Question).toarray()\n",
    "    labels = df.intent_id\n",
    "    features.shape\n",
    "    X_train, X_test,y_train, y_test = train_test_split(df['Question'],df['Intent'],random_state = 0)\n",
    "#transform the text into a vector based on the frequency of each word that occurs in the entire text\n",
    "    count_vector = CountVectorizer()\n",
    "    X_train_counts = count_vector.fit_transform(X_train)\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "# Multinomimal Naive bayes classifier suitable for classifcation with discreate features e.g word counts for text classifcation \n",
    "# we use it here to classify the different intents\n",
    "    clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "    return clf, count_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f789aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_question_to_intent(question):\n",
    "    clf,count_vector = algo_matcher()\n",
    "    intent=clf.predict(count_vect.transform([question]))\n",
    "    print(intent)\n",
    "    return intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8bb5b218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nutrition_Baby_Cakes_Sweets_Biscuits']\n"
     ]
    }
   ],
   "source": [
    "intent_given_question = match_question_to_intent(\"At what age do i start giving by baby sweets?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d56ae79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nutrition_Baby_Cakes_Sweets_Biscuits']\n"
     ]
    }
   ],
   "source": [
    "print(intent_given_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ecb5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
